{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.app.id', 'local-1729305703794'), ('spark.app.startTime', '1729305702806'), ('spark.executor.id', 'driver'), ('spark.driver.host', 'localhost'), ('spark.app.submitTime', '1729305702635'), ('spark.executor.cores', '4'), ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'), ('spark.driver.port', '55491'), ('spark.rdd.compress', 'True'), ('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false'), ('spark.driver.memory', '8g'), ('spark.serializer.objectStreamReset', '100'), ('spark.sql.shuffle.partitions', '28'), ('spark.master', 'local[*]'), ('spark.executor.memory', '8g'), ('spark.submit.pyFiles', ''), ('spark.app.name', 'OptimizedLocalSpark'), ('spark.submit.deployMode', 'client'), ('spark.ui.showConsoleProgress', 'true'), ('spark.cores.max', '12')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext\n",
    "# Check Configuration\n",
    "print(sc.getConf().getAll())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------+\n",
      "|SalesOrderNumber| OrderDate|  TotalDue|\n",
      "+----------------+----------+----------+\n",
      "|         SO71858|2008-01-04|15275.1977|\n",
      "|         SO71895|2008-03-22|  272.6468|\n",
      "|         SO71897|2008-04-10|14017.9083|\n",
      "|         SO71920|2008-05-15| 3293.7761|\n",
      "|         SO71774|2008-06-25|   972.785|\n",
      "|         SO71786|2008-07-03|   87.0851|\n",
      "|         SO71782|2008-08-13|42452.6519|\n",
      "|         SO71783|2008-08-16|43962.7901|\n",
      "|         SO71793|2008-09-21|32663.5609|\n",
      "|         SO71796|2008-10-11|63686.2708|\n",
      "|         SO71797|2008-10-25|86222.8072|\n",
      "|         SO81758|2009-01-14|18275.4871|\n",
      "|         SO81895|2009-03-30|  3172.468|\n",
      "|         SO81897|2009-04-12|16027.1903|\n",
      "|         SO81920|2009-05-20| 4529.8761|\n",
      "|         SO91774|2009-06-05| 19872.785|\n",
      "|         SO91786|2009-07-13| 5687.0901|\n",
      "|         SO91782|2009-08-19|30242.6519|\n",
      "|         SO91783|2009-09-25|50962.7901|\n",
      "|         SO91793|2009-10-18|41263.7609|\n",
      "+----------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, sum\n",
    "\n",
    "\n",
    "\n",
    "# Extended sample data\n",
    "data = [\n",
    "    (\"SO71858\", \"2008-01-04\", 15275.1977),\n",
    "    (\"SO71895\", \"2008-03-22\", 272.6468),\n",
    "    (\"SO71897\", \"2008-04-10\", 14017.9083),\n",
    "    (\"SO71920\", \"2008-05-15\", 3293.7761),\n",
    "    (\"SO71774\", \"2008-06-25\", 972.785),\n",
    "    (\"SO71786\", \"2008-07-03\", 87.0851),\n",
    "    (\"SO71782\", \"2008-08-13\", 42452.6519),\n",
    "    (\"SO71783\", \"2008-08-16\", 43962.7901),\n",
    "    (\"SO71793\", \"2008-09-21\", 32663.5609),\n",
    "    (\"SO71796\", \"2008-10-11\", 63686.2708),\n",
    "    (\"SO71797\", \"2008-10-25\", 86222.8072),\n",
    "    (\"SO81758\", \"2009-01-14\", 18275.4871),\n",
    "    (\"SO81895\", \"2009-03-30\", 3172.468),\n",
    "    (\"SO81897\", \"2009-04-12\", 16027.1903),\n",
    "    (\"SO81920\", \"2009-05-20\", 4529.8761),\n",
    "    (\"SO91774\", \"2009-06-05\", 19872.785),\n",
    "    (\"SO91786\", \"2009-07-13\", 5687.0901),\n",
    "    (\"SO91782\", \"2009-08-19\", 30242.6519),\n",
    "    (\"SO91783\", \"2009-09-25\", 50962.7901),\n",
    "    (\"SO91793\", \"2009-10-18\", 41263.7609),\n",
    "    (\"SO91896\", \"2009-11-05\", 73686.2908),\n",
    "    (\"SO71858\", \"2010-01-04\", 17275.1277),\n",
    "    (\"SO71895\", \"2010-03-22\", 3272.7468),\n",
    "    (\"SO71897\", \"2010-04-10\", 14417.9083),\n",
    "    (\"SO71920\", \"2010-05-15\", 1293.7761),\n",
    "    (\"SO71774\", \"2010-06-25\", 1472.785),\n",
    "    (\"SO71786\", \"2010-07-03\", 187.0851),\n",
    "    (\"SO71782\", \"2010-08-13\", 37452.6519),\n",
    "    (\"SO71783\", \"2010-09-16\", 43962.2901),\n",
    "    (\"SO71793\", \"2010-10-21\", 22663.5609)\n",
    "]\n",
    "\n",
    "# Define schema for DataFrame\n",
    "columns = [\"SalesOrderNumber\", \"OrderDate\", \"TotalDue\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Convert OrderDate to proper Date type\n",
    "df = df.withColumn(\"OrderDate\", col(\"OrderDate\").cast(\"date\"))\n",
    "\n",
    "# Register DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"Sales\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.cache()\n",
    "# Register DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"Sales\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|Year|  YTD_Total|\n",
      "+----+-----------+\n",
      "|2008|302907.4799|\n",
      "|2009|263720.3903|\n",
      "|2010|141997.9319|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql ( \"\"\"\n",
    "SELECT YEAR(OrderDate) AS Year, SUM(TotalDue) AS YTD_Total\n",
    "FROM Sales\n",
    "GROUP BY YEAR(OrderDate)\n",
    "ORDER BY Year\n",
    "\"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+\n",
      "|Year|Month|         MTD_Total|\n",
      "+----+-----+------------------+\n",
      "|2008|    1|        15275.1977|\n",
      "|2008|    3|          272.6468|\n",
      "|2008|    4|        14017.9083|\n",
      "|2008|    5|         3293.7761|\n",
      "|2008|    6|           972.785|\n",
      "|2008|    7|           87.0851|\n",
      "|2008|    8|         86415.442|\n",
      "|2008|    9|        32663.5609|\n",
      "|2008|   10|149909.07799999998|\n",
      "|2009|    1|        18275.4871|\n",
      "|2009|    3|          3172.468|\n",
      "|2009|    4|        16027.1903|\n",
      "|2009|    5|         4529.8761|\n",
      "|2009|    6|         19872.785|\n",
      "|2009|    7|         5687.0901|\n",
      "|2009|    8|        30242.6519|\n",
      "|2009|    9|        50962.7901|\n",
      "|2009|   10|        41263.7609|\n",
      "|2009|   11|        73686.2908|\n",
      "|2010|    1|        17275.1277|\n",
      "+----+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2 = spark.sql(\"\"\"\n",
    "SELECT YEAR(OrderDate) AS Year, MONTH(OrderDate) AS Month, SUM(TotalDue) AS MTD_Total\n",
    "FROM Sales\n",
    "GROUP BY YEAR(OrderDate), MONTH(OrderDate)\n",
    "ORDER BY Year, Month\n",
    "\"\"\")\n",
    "res2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------+------------------+------------------+------------------+------------------+\n",
      "|SalesOrderNumber| OrderDate|  TotalDue|               YTD|         YTD_Frame|         YTD_range|             MTD_3|\n",
      "+----------------+----------+----------+------------------+------------------+------------------+------------------+\n",
      "|         SO71858|2008-01-04|15275.1977|        15275.1977|        15275.1977|        15275.1977|        15275.1977|\n",
      "|         SO71895|2008-03-22|  272.6468|15547.844500000001|15547.844500000001|15547.844500000001|15547.844500000001|\n",
      "|         SO71897|2008-04-10|14017.9083|29565.752800000002|29565.752800000002|29565.752800000002|29565.752800000002|\n",
      "|         SO71920|2008-05-15| 3293.7761|32859.528900000005|32859.528900000005|32859.528900000005|        17584.3312|\n",
      "|         SO71774|2008-06-25|   972.785| 33832.31390000001| 33832.31390000001| 33832.31390000001|18284.469399999998|\n",
      "|         SO71786|2008-07-03|   87.0851|33919.399000000005|33919.399000000005|33919.399000000005|         4353.6462|\n",
      "|         SO71782|2008-08-13|42452.6519|        76372.0509|        76372.0509|        76372.0509|         43512.522|\n",
      "|         SO71783|2008-08-16|43962.7901|        120334.841|        120334.841|        120334.841| 86502.52709999999|\n",
      "|         SO71793|2008-09-21|32663.5609|       152998.4019|       152998.4019|       152998.4019|119079.00289999999|\n",
      "|         SO71796|2008-10-11|63686.2708|       216684.6727|       216684.6727|       216684.6727|       140312.6218|\n",
      "|         SO71797|2008-10-25|86222.8072|       302907.4799|       302907.4799|       302907.4799|       182572.6389|\n",
      "|         SO81758|2009-01-14|18275.4871|        18275.4871|        18275.4871|        18275.4871|        18275.4871|\n",
      "|         SO81895|2009-03-30|  3172.468|        21447.9551|        21447.9551|        21447.9551|        21447.9551|\n",
      "|         SO81897|2009-04-12|16027.1903|        37475.1454|        37475.1454|        37475.1454|        37475.1454|\n",
      "|         SO81920|2009-05-20| 4529.8761|        42005.0215|        42005.0215|        42005.0215|        23729.5344|\n",
      "|         SO91774|2009-06-05| 19872.785|61877.806500000006|61877.806500000006|61877.806500000006|        40429.8514|\n",
      "|         SO91786|2009-07-13| 5687.0901| 67564.89660000001| 67564.89660000001| 67564.89660000001|30089.751200000002|\n",
      "|         SO91782|2009-08-19|30242.6519|        97807.5485|        97807.5485|        97807.5485|         55802.527|\n",
      "|         SO91783|2009-09-25|50962.7901|148770.33860000002|148770.33860000002|148770.33860000002|        86892.5321|\n",
      "|         SO91793|2009-10-18|41263.7609|       190034.0995|       190034.0995|       190034.0995|       122469.2029|\n",
      "+----------------+----------+----------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res4 = spark.sql(\"\"\"\n",
    "\n",
    "select SalesOrderNumber, OrderDate, TotalDue, \n",
    "sum(TotalDue) over (partition by year(OrderDate) order by OrderDate) as YTD,\n",
    "sum(TotalDue) over (partition by year(OrderDate) order by OrderDate rows between unbounded preceding and current row) as YTD_Frame,\n",
    "sum(TotalDue) over (partition by year(OrderDate) order by OrderDate range between unbounded preceding and current row) as YTD_range,\n",
    "sum(TotalDue) over (partition by year(OrderDate) order by OrderDate rows between 2 preceding and current row) as MTD_3\n",
    "from Sales\n",
    "\n",
    "\"\"\")\n",
    "res4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|Year|  YTD_Total|\n",
      "+----+-----------+\n",
      "|2008|302907.4799|\n",
      "|2009|263720.3903|\n",
      "|2010|141997.9319|\n",
      "+----+-----------+\n",
      "\n",
      "+----+-----+------------------+\n",
      "|Year|Month|         MTD_Total|\n",
      "+----+-----+------------------+\n",
      "|2008|    1|        15275.1977|\n",
      "|2008|    3|          272.6468|\n",
      "|2008|    4|        14017.9083|\n",
      "|2008|    5|         3293.7761|\n",
      "|2008|    6|           972.785|\n",
      "|2008|    7|           87.0851|\n",
      "|2008|    8|         86415.442|\n",
      "|2008|    9|        32663.5609|\n",
      "|2008|   10|149909.07799999998|\n",
      "|2009|    1|        18275.4871|\n",
      "|2009|    3|          3172.468|\n",
      "|2009|    4|        16027.1903|\n",
      "|2009|    5|         4529.8761|\n",
      "|2009|    6|         19872.785|\n",
      "|2009|    7|         5687.0901|\n",
      "|2009|    8|        30242.6519|\n",
      "|2009|    9|        50962.7901|\n",
      "|2009|   10|        41263.7609|\n",
      "|2009|   11|        73686.2908|\n",
      "|2010|    1|        17275.1277|\n",
      "+----+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ytd = df.groupBy(year(\"OrderDate\").alias(\"Year\")).agg(sum(\"TotalDue\").alias(\"YTD_Total\"))\n",
    "df_ytd .orderBy(\"Year\").show()\n",
    "\n",
    "\n",
    "mtd_df = df.groupBy(year(\"OrderDate\").alias(\"Year\"), month(\"OrderDate\").alias(\"Month\")).agg(sum(\"TotalDue\").alias(\"MTD_Total\"))\n",
    "mtd_df.orderBy(\"Year\", \"Month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+------------------+\n",
      "|Year|Month|         MTD_Total|         YTD_Total|\n",
      "+----+-----+------------------+------------------+\n",
      "|2008|    1|        15275.1977|        15275.1977|\n",
      "|2008|    3|          272.6468|15547.844500000001|\n",
      "|2008|    4|        14017.9083|29565.752800000002|\n",
      "|2008|    5|         3293.7761|32859.528900000005|\n",
      "|2008|    6|           972.785| 33832.31390000001|\n",
      "|2008|    7|           87.0851|33919.399000000005|\n",
      "|2008|    8|         86415.442|        120334.841|\n",
      "|2008|    9|        32663.5609|       152998.4019|\n",
      "|2008|   10|149909.07799999998|       302907.4799|\n",
      "|2009|    1|        18275.4871|        18275.4871|\n",
      "|2009|    3|          3172.468|        21447.9551|\n",
      "|2009|    4|        16027.1903|        37475.1454|\n",
      "|2009|    5|         4529.8761|        42005.0215|\n",
      "|2009|    6|         19872.785|61877.806500000006|\n",
      "|2009|    7|         5687.0901| 67564.89660000001|\n",
      "|2009|    8|        30242.6519|        97807.5485|\n",
      "|2009|    9|        50962.7901|148770.33860000002|\n",
      "|2009|   10|        41263.7609|       190034.0995|\n",
      "|2009|   11|        73686.2908|       263720.3903|\n",
      "|2010|    1|        17275.1277|        17275.1277|\n",
      "+----+-----+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month, sum\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark Session (assuming it's already created)\n",
    "\n",
    "# Step 1: Calculate Month-to-Date (MTD) totals\n",
    "mtd_df = df.groupBy(year(\"OrderDate\").alias(\"Year\"), month(\"OrderDate\").alias(\"Month\")) .agg( sum(\"TotalDue\").alias(\"MTD_Total\") )\n",
    "\n",
    "# Step 2: Define a Window for YTD Calculation\n",
    "ytd_window = Window.partitionBy(\"Year\").orderBy(\"Month\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Step 3: Add the YTD_Total column using the MTD_Total values and the Window function\n",
    "ytd_mtd_df = mtd_df.withColumn(\"YTD_Total\", sum(\"MTD_Total\").over(ytd_window)).orderBy(\"Year\", \"Month\")\n",
    "\n",
    "# Show the final result\n",
    "ytd_mtd_df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
