{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+---------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|ManagerID|\n",
      "+----------+------------+----------+------+---------+\n",
      "|         1|       Alice|        HR|  5000|     null|\n",
      "|         2|         Bob|        HR|  4500|        1|\n",
      "|         3|     Charlie|        HR|  5500|        1|\n",
      "|         4|       David|        IT|  6000|     null|\n",
      "|         5|         Eve|        IT|  6500|        4|\n",
      "|         6|       Frank|        IT|  5800|        4|\n",
      "|         7|       Grace|   Finance|  5200|     null|\n",
      "|         8|       Heidi|   Finance|  4800|        7|\n",
      "|         9|        Ivan|   Finance|  5300|        7|\n",
      "|        10|        Judy|     Sales|  4000|     null|\n",
      "|        11|       Kevin|     Sales|  4200|       10|\n",
      "|        12|       Laura|     Sales|  4500|       10|\n",
      "|        13|     Mallory| Marketing|  4900|     null|\n",
      "|        14|        Niaj| Marketing|  5000|       13|\n",
      "|        15|       Oscar| Marketing|  4600|       13|\n",
      "+----------+------------+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Sample employee data\n",
    "data = [\n",
    "    Row(EmployeeID=1, EmployeeName=\"Alice\", Department=\"HR\", Salary=5000, ManagerID=None),\n",
    "    Row(EmployeeID=2, EmployeeName=\"Bob\", Department=\"HR\", Salary=4500, ManagerID=1),\n",
    "    Row(EmployeeID=3, EmployeeName=\"Charlie\", Department=\"HR\", Salary=5500, ManagerID=1),\n",
    "    Row(EmployeeID=4, EmployeeName=\"David\", Department=\"IT\", Salary=6000, ManagerID=None),\n",
    "    Row(EmployeeID=5, EmployeeName=\"Eve\", Department=\"IT\", Salary=6500, ManagerID=4),\n",
    "    Row(EmployeeID=6, EmployeeName=\"Frank\", Department=\"IT\", Salary=5800, ManagerID=4),\n",
    "    Row(EmployeeID=7, EmployeeName=\"Grace\", Department=\"Finance\", Salary=5200, ManagerID=None),\n",
    "    Row(EmployeeID=8, EmployeeName=\"Heidi\", Department=\"Finance\", Salary=4800, ManagerID=7),\n",
    "    Row(EmployeeID=9, EmployeeName=\"Ivan\", Department=\"Finance\", Salary=5300, ManagerID=7),\n",
    "    Row(EmployeeID=10, EmployeeName=\"Judy\", Department=\"Sales\", Salary=4000, ManagerID=None),\n",
    "    Row(EmployeeID=11, EmployeeName=\"Kevin\", Department=\"Sales\", Salary=4200, ManagerID=10),\n",
    "    Row(EmployeeID=12, EmployeeName=\"Laura\", Department=\"Sales\", Salary=4500, ManagerID=10),\n",
    "    Row(EmployeeID=13, EmployeeName=\"Mallory\", Department=\"Marketing\", Salary=4900, ManagerID=None),\n",
    "    Row(EmployeeID=14, EmployeeName=\"Niaj\", Department=\"Marketing\", Salary=5000, ManagerID=13),\n",
    "    Row(EmployeeID=15, EmployeeName=\"Oscar\", Department=\"Marketing\", Salary=4600, ManagerID=13)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data)\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"Employees\")\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+----------+------+---------+\n",
      "|EmployeeID|EmployeeName|Manager_Name|Department|Salary|ManagerID|\n",
      "+----------+------------+------------+----------+------+---------+\n",
      "|         3|     Charlie|       Alice|        HR|  5500|     null|\n",
      "|         5|         Eve|       David|        IT|  6500|     null|\n",
      "|         9|        Ivan|       Grace|   Finance|  5300|     null|\n",
      "|        11|       Kevin|        Judy|     Sales|  4200|     null|\n",
      "|        12|       Laura|        Judy|     Sales|  4500|     null|\n",
      "|        14|        Niaj|     Mallory| Marketing|  5000|     null|\n",
      "+----------+------------+------------+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql(\"\"\" \n",
    "    Select e.EmployeeID,  e.EmployeeName, m.EmployeeName as Manager_Name,   e. Department ,  e. Salary ,  m. ManagerID from Employees e \n",
    "    join Employees m \n",
    "    on e.ManagerID = m.EmployeeID\n",
    "     and e.Salary > m.Salary  \n",
    "                \"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "|EmployeeID|EmployeeName|Department|EmployeeSalary|ManagerName|ManagerSalary|\n",
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "|         3|     Charlie|        HR|          5500|      Alice|         5000|\n",
      "|         5|         Eve|        IT|          6500|      David|         6000|\n",
      "|         9|        Ivan|   Finance|          5300|      Grace|         5200|\n",
      "|        11|       Kevin|     Sales|          4200|       Judy|         4000|\n",
      "|        12|       Laura|     Sales|          4500|       Judy|         4000|\n",
      "|        14|        Niaj| Marketing|          5000|    Mallory|         4900|\n",
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res5 = spark.sql(\"\"\"  \n",
    "\n",
    "SELECT emp.EmployeeID, emp.EmployeeName, emp.Department, emp.Salary AS EmployeeSalary,\n",
    "       mgr.EmployeeName AS ManagerName, mgr.Salary AS ManagerSalary\n",
    "FROM Employees emp\n",
    "INNER JOIN Employees mgr \n",
    "ON emp.ManagerID = mgr.EmployeeID\n",
    "WHERE emp.Salary > mgr.Salary\n",
    "            \n",
    "                 \"\"\")\n",
    "res5.show()\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------------+-------------+\n",
      "|EmployeeID|EmployeeName|Department|EmployeeSalary|ManagerSalary|\n",
      "+----------+------------+----------+--------------+-------------+\n",
      "|         3|     Charlie|        HR|          5500|         5000|\n",
      "|         5|         Eve|        IT|          6500|         6000|\n",
      "|         9|        Ivan|   Finance|          5300|         5200|\n",
      "|        11|       Kevin|     Sales|          4200|         4000|\n",
      "|        12|       Laura|     Sales|          4500|         4000|\n",
      "|        14|        Niaj| Marketing|          5000|         4900|\n",
      "+----------+------------+----------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query with CTE to find employees with a higher salary than their manager\n",
    "advanced_query = \"\"\"\n",
    "WITH ManagerSalaries AS (\n",
    "    SELECT EmployeeID AS ManagerID, Salary AS ManagerSalary\n",
    "    FROM Employees\n",
    ")\n",
    "\n",
    "\n",
    "SELECT e.EmployeeID, e.EmployeeName, e.Department, e.Salary AS EmployeeSalary,\n",
    "       m.ManagerSalary\n",
    "FROM Employees e\n",
    "LEFT JOIN ManagerSalaries m \n",
    "ON e.ManagerID = m.ManagerID\n",
    "WHERE e.Salary > m.ManagerSalary\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "advanced_sql_result = spark.sql(advanced_query)\n",
    "advanced_sql_result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "|EmployeeID|EmployeeName|Department|EmployeeSalary|ManagerName|ManagerSalary|\n",
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "|         3|     Charlie|        HR|          5500|      Alice|         5000|\n",
      "|         5|         Eve|        IT|          6500|      David|         6000|\n",
      "|         9|        Ivan|   Finance|          5300|      Grace|         5200|\n",
      "|        11|       Kevin|     Sales|          4200|       Judy|         4000|\n",
      "|        12|       Laura|     Sales|          4500|       Judy|         4000|\n",
      "|        14|        Niaj| Marketing|          5000|    Mallory|         4900|\n",
      "+----------+------------+----------+--------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Self-join the DataFrame to match employees with their managers\n",
    "employee_manager_df = df.alias(\"emp\").join(\n",
    "    df.alias(\"mgr\"),\n",
    "    col(\"emp.ManagerID\") == col(\"mgr.EmployeeID\"),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"emp.EmployeeID\").alias(\"EmployeeID\"),\n",
    "    col(\"emp.EmployeeName\").alias(\"EmployeeName\"),\n",
    "    col(\"emp.Department\").alias(\"Department\"),\n",
    "    col(\"emp.Salary\").alias(\"EmployeeSalary\"),\n",
    "    col(\"mgr.EmployeeName\").alias(\"ManagerName\"),\n",
    "    col(\"mgr.Salary\").alias(\"ManagerSalary\")\n",
    ")\n",
    "\n",
    "# Step 2: Filter to find employees with a salary greater than their manager's salary\n",
    "result_df = employee_manager_df.filter(col(\"EmployeeSalary\") > col(\"ManagerSalary\"))\n",
    "\n",
    "# Show the result\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
