{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\pyspark_advanced-coding_interview'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+----------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|  HireDate|\n",
      "+----------+------------+----------+------+----------+\n",
      "|         1|       Alice|        HR|  5000|2022-05-15|\n",
      "|         2|         Bob|        HR|  4500|2020-03-10|\n",
      "|         3|     Charlie|        HR|  5500|2021-07-01|\n",
      "|         4|       David|        IT|  6000|2019-01-25|\n",
      "|         5|         Eve|        IT|  6500|2022-08-30|\n",
      "|         6|       Frank|        IT|  5800|2021-06-14|\n",
      "|         7|       Grace|   Finance|  5200|2020-11-20|\n",
      "|         8|       Heidi|   Finance|  4800|2021-12-01|\n",
      "|         9|        Ivan|   Finance|  5300|2018-07-18|\n",
      "|        10|        Judy|     Sales|  4000|2023-01-05|\n",
      "|        11|       Kevin|     Sales|  4200|2021-09-13|\n",
      "|        12|       Laura|     Sales|  4500|2020-04-02|\n",
      "|        13|     Mallory| Marketing|  4900|2023-03-25|\n",
      "|        14|        Niaj| Marketing|  5000|2021-02-10|\n",
      "|        15|       Oscar| Marketing|  4600|2019-10-03|\n",
      "+----------+------------+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\n",
    "# Sample employee data\n",
    "data = [\n",
    "    Row(EmployeeID=1, EmployeeName=\"Alice\", Department=\"HR\", Salary=5000, HireDate=date(2022, 5, 15)),\n",
    "    Row(EmployeeID=2, EmployeeName=\"Bob\", Department=\"HR\", Salary=4500, HireDate=date(2020, 3, 10)),\n",
    "    Row(EmployeeID=3, EmployeeName=\"Charlie\", Department=\"HR\", Salary=5500, HireDate=date(2021, 7, 1)),\n",
    "    Row(EmployeeID=4, EmployeeName=\"David\", Department=\"IT\", Salary=6000, HireDate=date(2019, 1, 25)),\n",
    "    Row(EmployeeID=5, EmployeeName=\"Eve\", Department=\"IT\", Salary=6500, HireDate=date(2022, 8, 30)),\n",
    "    Row(EmployeeID=6, EmployeeName=\"Frank\", Department=\"IT\", Salary=5800, HireDate=date(2021, 6, 14)),\n",
    "    Row(EmployeeID=7, EmployeeName=\"Grace\", Department=\"Finance\", Salary=5200, HireDate=date(2020, 11, 20)),\n",
    "    Row(EmployeeID=8, EmployeeName=\"Heidi\", Department=\"Finance\", Salary=4800, HireDate=date(2021, 12, 1)),\n",
    "    Row(EmployeeID=9, EmployeeName=\"Ivan\", Department=\"Finance\", Salary=5300, HireDate=date(2018, 7, 18)),\n",
    "    Row(EmployeeID=10, EmployeeName=\"Judy\", Department=\"Sales\", Salary=4000, HireDate=date(2023, 1, 5)),\n",
    "    Row(EmployeeID=11, EmployeeName=\"Kevin\", Department=\"Sales\", Salary=4200, HireDate=date(2021, 9, 13)),\n",
    "    Row(EmployeeID=12, EmployeeName=\"Laura\", Department=\"Sales\", Salary=4500, HireDate=date(2020, 4, 2)),\n",
    "    Row(EmployeeID=13, EmployeeName=\"Mallory\", Department=\"Marketing\", Salary=4900, HireDate=date(2023, 3, 25)),\n",
    "    Row(EmployeeID=14, EmployeeName=\"Niaj\", Department=\"Marketing\", Salary=5000, HireDate=date(2021, 2, 10)),\n",
    "    Row(EmployeeID=15, EmployeeName=\"Oscar\", Department=\"Marketing\", Salary=4600, HireDate=date(2019, 10, 3))\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data)\n",
    "df.createOrReplaceTempView('Employees')\n",
    "df.cache()\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+---------+----------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|ManagerID|  HireDate|\n",
      "+----------+------------+----------+------+---------+----------+\n",
      "|         1|       Alice|        HR|5000.0|     null|2020-10-10|\n",
      "|         2|         Bob|        HR|4500.0|        1|2018-09-15|\n",
      "|         3|     Charlie|        HR|5500.0|        1|2019-08-20|\n",
      "|         4|       David|        IT|6000.0|     null|2022-01-05|\n",
      "|         5|         Eve|        IT|6500.0|        4|2021-03-30|\n",
      "|         6|       Frank|        IT|5800.0|        4|2020-07-14|\n",
      "|         7|       Grace|   Finance|5200.0|     null|2019-06-01|\n",
      "|         8|       Heidi|   Finance|4800.0|        7|2020-02-17|\n",
      "|         9|        Ivan|   Finance|5300.0|        7|2017-11-19|\n",
      "|        10|        Judy|     Sales|4000.0|     null|2021-04-10|\n",
      "|        11|       Kevin|     Sales|4200.0|       10|2020-05-07|\n",
      "|        12|       Laura|     Sales|4500.0|       10|2019-07-12|\n",
      "|        13|     Mallory| Marketing|4900.0|     null|2019-03-01|\n",
      "|        14|        Niaj| Marketing|5000.0|       13|2021-08-15|\n",
      "|        15|       Oscar| Marketing|4600.0|       13|2020-01-25|\n",
      "+----------+------------+----------+------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Define schema using StructType and StructField\n",
    "schema = StructType([\n",
    "    StructField(\"EmployeeID\", IntegerType(), True),\n",
    "    StructField(\"EmployeeName\", StringType(), True),\n",
    "    StructField(\"Department\", StringType(), True),\n",
    "    StructField(\"Salary\", DoubleType(), True),\n",
    "    StructField(\"ManagerID\", IntegerType(), True),\n",
    "    StructField(\"HireDate\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (EmployeeID, EmployeeName, Department, Salary, ManagerID, HireDate)\n",
    "data = [\n",
    "    (1, \"Alice\", \"HR\", 5000.0, None, datetime.strptime(\"2020-10-10\", \"%Y-%m-%d\").date()),\n",
    "    (2, \"Bob\", \"HR\", 4500.0, 1, datetime.strptime(\"2018-09-15\", \"%Y-%m-%d\").date()),\n",
    "    (3, \"Charlie\", \"HR\", 5500.0, 1, datetime.strptime(\"2019-08-20\", \"%Y-%m-%d\").date()),\n",
    "    (4, \"David\", \"IT\", 6000.0, None, datetime.strptime(\"2022-01-05\", \"%Y-%m-%d\").date()),\n",
    "    (5, \"Eve\", \"IT\", 6500.0, 4, datetime.strptime(\"2021-03-30\", \"%Y-%m-%d\").date()),\n",
    "    (6, \"Frank\", \"IT\", 5800.0, 4, datetime.strptime(\"2020-07-14\", \"%Y-%m-%d\").date()),\n",
    "    (7, \"Grace\", \"Finance\", 5200.0, None, datetime.strptime(\"2019-06-01\", \"%Y-%m-%d\").date()),\n",
    "    (8, \"Heidi\", \"Finance\", 4800.0, 7, datetime.strptime(\"2020-02-17\", \"%Y-%m-%d\").date()),\n",
    "    (9, \"Ivan\", \"Finance\", 5300.0, 7, datetime.strptime(\"2017-11-19\", \"%Y-%m-%d\").date()),\n",
    "    (10, \"Judy\", \"Sales\", 4000.0, None, datetime.strptime(\"2021-04-10\", \"%Y-%m-%d\").date()),\n",
    "    (11, \"Kevin\", \"Sales\", 4200.0, 10, datetime.strptime(\"2020-05-07\", \"%Y-%m-%d\").date()),\n",
    "    (12, \"Laura\", \"Sales\", 4500.0, 10, datetime.strptime(\"2019-07-12\", \"%Y-%m-%d\").date()),\n",
    "    (13, \"Mallory\", \"Marketing\", 4900.0, None, datetime.strptime(\"2019-03-01\", \"%Y-%m-%d\").date()),\n",
    "    (14, \"Niaj\", \"Marketing\", 5000.0, 13, datetime.strptime(\"2021-08-15\", \"%Y-%m-%d\").date()),\n",
    "    (15, \"Oscar\", \"Marketing\", 4600.0, 13, datetime.strptime(\"2020-01-25\", \"%Y-%m-%d\").date())\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df1 = spark.createDataFrame(data, schema)\n",
    "df1.createOrReplaceTempView(\"Employees\")\n",
    "\n",
    "df1.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EmployeeID', 'bigint'),\n",
       " ('EmployeeName', 'string'),\n",
       " ('Department', 'string'),\n",
       " ('Salary', 'bigint'),\n",
       " ('HireDate', 'date')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+---------+----------+\n",
      "|EmployeeID|EmployeeName|Department|NewSalary|  HireDate|\n",
      "+----------+------------+----------+---------+----------+\n",
      "|         1|       Alice|        HR|   5500.0|2022-05-15|\n",
      "|         2|         Bob|        HR|   4950.0|2020-03-10|\n",
      "|         3|     Charlie|        HR|   6050.0|2021-07-01|\n",
      "|         4|       David|        IT|   6600.0|2019-01-25|\n",
      "|         5|         Eve|        IT|   7150.0|2022-08-30|\n",
      "|         6|       Frank|        IT|   6380.0|2021-06-14|\n",
      "|         7|       Grace|   Finance|   5720.0|2020-11-20|\n",
      "|         8|       Heidi|   Finance|   5280.0|2021-12-01|\n",
      "|         9|        Ivan|   Finance|   5830.0|2018-07-18|\n",
      "|        10|        Judy|     Sales|   4000.0|2023-01-05|\n",
      "|        11|       Kevin|     Sales|   4620.0|2021-09-13|\n",
      "|        12|       Laura|     Sales|   4950.0|2020-04-02|\n",
      "|        13|     Mallory| Marketing|   4900.0|2023-03-25|\n",
      "|        14|        Niaj| Marketing|   5500.0|2021-02-10|\n",
      "|        15|       Oscar| Marketing|   5060.0|2019-10-03|\n",
      "+----------+------------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query using DATE_ADD for increment logic\n",
    "query2 = spark.sql(\"\"\"\n",
    "SELECT EmployeeID, EmployeeName, Department,\n",
    "       CASE WHEN HireDate <= DATE_ADD(current_date(), -730) THEN Salary * 1.1 ELSE Salary END AS NewSalary, HireDate\n",
    "FROM Employees\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "query2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+---------+----------+\n",
      "|EmployeeID|EmployeeName|Department|NewSalary|  HireDate|\n",
      "+----------+------------+----------+---------+----------+\n",
      "|         1|       Alice|        HR|   5500.0|2022-05-15|\n",
      "|         2|         Bob|        HR|   4950.0|2020-03-10|\n",
      "|         3|     Charlie|        HR|   6050.0|2021-07-01|\n",
      "|         4|       David|        IT|   6600.0|2019-01-25|\n",
      "|         5|         Eve|        IT|   7150.0|2022-08-30|\n",
      "|         6|       Frank|        IT|   6380.0|2021-06-14|\n",
      "|         7|       Grace|   Finance|   5720.0|2020-11-20|\n",
      "|         8|       Heidi|   Finance|   5280.0|2021-12-01|\n",
      "|         9|        Ivan|   Finance|   5830.0|2018-07-18|\n",
      "|        10|        Judy|     Sales|   4000.0|2023-01-05|\n",
      "|        11|       Kevin|     Sales|   4620.0|2021-09-13|\n",
      "|        12|       Laura|     Sales|   4950.0|2020-04-02|\n",
      "|        13|     Mallory| Marketing|   4900.0|2023-03-25|\n",
      "|        14|        Niaj| Marketing|   5500.0|2021-02-10|\n",
      "|        15|       Oscar| Marketing|   5060.0|2019-10-03|\n",
      "+----------+------------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Query to increment salaries for employees with 2+ years in the organization\n",
    "query = spark.sql(\"\"\"\n",
    "SELECT EmployeeID, EmployeeName, Department,\n",
    "       CASE WHEN DATEDIFF(current_date(), HireDate) >= 730 THEN Salary * 1.1 ELSE Salary END AS NewSalary,HireDate\n",
    "FROM Employees\n",
    "\"\"\")\n",
    "\n",
    "# Execute the query\n",
    "query.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+----------+---------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|  HireDate|NewSalary|\n",
      "+----------+------------+----------+------+----------+---------+\n",
      "|         1|       Alice|        HR|  5000|2022-05-15|  5500.00|\n",
      "|         2|         Bob|        HR|  4500|2020-03-10|  4950.00|\n",
      "|         3|     Charlie|        HR|  5500|2021-07-01|  6050.00|\n",
      "|         4|       David|        IT|  6000|2019-01-25|  6600.00|\n",
      "|         5|         Eve|        IT|  6500|2022-08-30|  7150.00|\n",
      "|         6|       Frank|        IT|  5800|2021-06-14|  6380.00|\n",
      "|         7|       Grace|   Finance|  5200|2020-11-20|  5720.00|\n",
      "|         8|       Heidi|   Finance|  4800|2021-12-01|  5280.00|\n",
      "|         9|        Ivan|   Finance|  5300|2018-07-18|  5830.00|\n",
      "|        10|        Judy|     Sales|  4000|2023-01-05|  4000.00|\n",
      "|        11|       Kevin|     Sales|  4200|2021-09-13|  4620.00|\n",
      "|        12|       Laura|     Sales|  4500|2020-04-02|  4950.00|\n",
      "|        13|     Mallory| Marketing|  4900|2023-03-25|  4900.00|\n",
      "|        14|        Niaj| Marketing|  5000|2021-02-10|  5500.00|\n",
      "|        15|       Oscar| Marketing|  4600|2019-10-03|  5060.00|\n",
      "+----------+------------+----------+------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql(\"\"\" \n",
    "\n",
    "SELECT EmployeeID, EmployeeName, Department, Salary, HireDate,\n",
    "       CASE WHEN DATEDIFF(CURRENT_DATE(), HireDate) / 365 >= 2 THEN Salary * 1.10 ELSE Salary END AS NewSalary\n",
    "FROM Employees\n",
    "             \"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+-----------------+----------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|        NewSalary|  HireDate|\n",
      "+----------+------------+----------+------+-----------------+----------+\n",
      "|         1|       Alice|        HR|  5000|           5500.0|2022-05-15|\n",
      "|         2|         Bob|        HR|  4500|           4950.0|2020-03-10|\n",
      "|         3|     Charlie|        HR|  5500|6050.000000000001|2021-07-01|\n",
      "|         4|       David|        IT|  6000|6600.000000000001|2019-01-25|\n",
      "|         5|         Eve|        IT|  6500|7150.000000000001|2022-08-30|\n",
      "|         6|       Frank|        IT|  5800|6380.000000000001|2021-06-14|\n",
      "|         7|       Grace|   Finance|  5200|5720.000000000001|2020-11-20|\n",
      "|         8|       Heidi|   Finance|  4800|           5280.0|2021-12-01|\n",
      "|         9|        Ivan|   Finance|  5300|5830.000000000001|2018-07-18|\n",
      "|        10|        Judy|     Sales|  4000|           4000.0|2023-01-05|\n",
      "|        11|       Kevin|     Sales|  4200|           4620.0|2021-09-13|\n",
      "|        12|       Laura|     Sales|  4500|           4950.0|2020-04-02|\n",
      "|        13|     Mallory| Marketing|  4900|           4900.0|2023-03-25|\n",
      "|        14|        Niaj| Marketing|  5000|           5500.0|2021-02-10|\n",
      "|        15|       Oscar| Marketing|  4600|           5060.0|2019-10-03|\n",
      "+----------+------------+----------+------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, current_date, datediff\n",
    "\n",
    "# Define the increment percentage (e.g., 10%)\n",
    "increment_percentage = 0.10\n",
    "\n",
    "# Calculate tenure in days and convert to years\n",
    "df_with_increment = df \\\n",
    ".withColumn(\"YearsWithOrg\", datediff(current_date(), col(\"HireDate\")) / 365) \\\n",
    ".withColumn(\"NewSalary\", when(col(\"YearsWithOrg\") >= 2, col(\"Salary\") * (1 + increment_percentage)).otherwise(col(\"Salary\")))\n",
    "\n",
    "\n",
    "# Show updated salary details\n",
    "df_with_increment.select(\"EmployeeID\", \"EmployeeName\", \"Department\", \"Salary\", \"NewSalary\",\"HireDate\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+-----------------+----------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|        NewSalary|  HireDate|\n",
      "+----------+------------+----------+------+-----------------+----------+\n",
      "|         1|       Alice|        HR|  5000|           5500.0|2022-05-15|\n",
      "|         2|         Bob|        HR|  4500|           4950.0|2020-03-10|\n",
      "|         3|     Charlie|        HR|  5500|6050.000000000001|2021-07-01|\n",
      "|         4|       David|        IT|  6000|6600.000000000001|2019-01-25|\n",
      "|         5|         Eve|        IT|  6500|7150.000000000001|2022-08-30|\n",
      "|         6|       Frank|        IT|  5800|6380.000000000001|2021-06-14|\n",
      "|         7|       Grace|   Finance|  5200|5720.000000000001|2020-11-20|\n",
      "|         8|       Heidi|   Finance|  4800|           5280.0|2021-12-01|\n",
      "|         9|        Ivan|   Finance|  5300|5830.000000000001|2018-07-18|\n",
      "|        10|        Judy|     Sales|  4000|             null|2023-01-05|\n",
      "|        11|       Kevin|     Sales|  4200|           4620.0|2021-09-13|\n",
      "|        12|       Laura|     Sales|  4500|           4950.0|2020-04-02|\n",
      "|        13|     Mallory| Marketing|  4900|             null|2023-03-25|\n",
      "|        14|        Niaj| Marketing|  5000|           5500.0|2021-02-10|\n",
      "|        15|       Oscar| Marketing|  4600|           5060.0|2019-10-03|\n",
      "+----------+------------+----------+------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from datetime import datetime\n",
    "\n",
    "# Define a UDF to calculate the new salary\n",
    "def calculate_new_salary(salary, hire_date):\n",
    "    current_date = datetime.now().date()\n",
    "    tenure_years = (current_date - hire_date).days / 365\n",
    "    if tenure_years >= 2:\n",
    "        return salary * 1.10  # 10% increment\n",
    "    else:\n",
    "        return salary\n",
    "\n",
    "# Register the UDF\n",
    "increment_udf = udf(calculate_new_salary, DoubleType())\n",
    "\n",
    "# Apply the UDF to calculate new salaries\n",
    "df_with_new_salary = df.withColumn(\"NewSalary\", increment_udf(col(\"Salary\"), col(\"HireDate\")))\n",
    "\n",
    "# Show the result\n",
    "df_with_new_salary.select(\"EmployeeID\", \"EmployeeName\", \"Department\", \"Salary\", \"NewSalary\", \"HireDate\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+----------+-----------------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|  HireDate|        NewSalary|\n",
      "+----------+------------+----------+------+----------+-----------------+\n",
      "|         1|       Alice|        HR|  5000|2022-05-15|           5500.0|\n",
      "|         2|         Bob|        HR|  4500|2020-03-10|           4950.0|\n",
      "|         3|     Charlie|        HR|  5500|2021-07-01|6050.000000000001|\n",
      "|         4|       David|        IT|  6000|2019-01-25|6600.000000000001|\n",
      "|         5|         Eve|        IT|  6500|2022-08-30|7150.000000000001|\n",
      "|         6|       Frank|        IT|  5800|2021-06-14|6380.000000000001|\n",
      "|         7|       Grace|   Finance|  5200|2020-11-20|5720.000000000001|\n",
      "|         8|       Heidi|   Finance|  4800|2021-12-01|           5280.0|\n",
      "|         9|        Ivan|   Finance|  5300|2018-07-18|5830.000000000001|\n",
      "|        10|        Judy|     Sales|  4000|2023-01-05|           4000.0|\n",
      "|        11|       Kevin|     Sales|  4200|2021-09-13|           4620.0|\n",
      "|        12|       Laura|     Sales|  4500|2020-04-02|           4950.0|\n",
      "|        13|     Mallory| Marketing|  4900|2023-03-25|           4900.0|\n",
      "|        14|        Niaj| Marketing|  5000|2021-02-10|           5500.0|\n",
      "|        15|       Oscar| Marketing|  4600|2019-10-03|           5060.0|\n",
      "+----------+------------+----------+------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Increment salary for employees with 2+ years using PySpark DataFrame methods\n",
    "df_with_increment = df.withColumn(\n",
    "    \"NewSalary\",\n",
    "    F.when(F.datediff(F.current_date(), F.col(\"HireDate\")) >= 730, F.col(\"Salary\") * 1.1).otherwise(F.col(\"Salary\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_with_increment.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------+----------+-----------------+\n",
      "|EmployeeID|EmployeeName|Department|Salary|  HireDate|        NewSalary|\n",
      "+----------+------------+----------+------+----------+-----------------+\n",
      "|         1|       Alice|        HR|  5000|2022-05-15|           5500.0|\n",
      "|         2|         Bob|        HR|  4500|2020-03-10|           4950.0|\n",
      "|         3|     Charlie|        HR|  5500|2021-07-01|6050.000000000001|\n",
      "|         4|       David|        IT|  6000|2019-01-25|6600.000000000001|\n",
      "|         5|         Eve|        IT|  6500|2022-08-30|7150.000000000001|\n",
      "|         6|       Frank|        IT|  5800|2021-06-14|6380.000000000001|\n",
      "|         7|       Grace|   Finance|  5200|2020-11-20|5720.000000000001|\n",
      "|         8|       Heidi|   Finance|  4800|2021-12-01|           5280.0|\n",
      "|         9|        Ivan|   Finance|  5300|2018-07-18|5830.000000000001|\n",
      "|        11|       Kevin|     Sales|  4200|2021-09-13|           4620.0|\n",
      "|        12|       Laura|     Sales|  4500|2020-04-02|           4950.0|\n",
      "|        14|        Niaj| Marketing|  5000|2021-02-10|           5500.0|\n",
      "|        15|       Oscar| Marketing|  4600|2019-10-03|           5060.0|\n",
      "|        10|        Judy|     Sales|  4000|2023-01-05|           4000.0|\n",
      "|        13|     Mallory| Marketing|  4900|2023-03-25|           4900.0|\n",
      "+----------+------------+----------+------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate employees with 2+ years and apply salary increment\n",
    "two_years_ago = F.date_sub(F.current_date(), 730)\n",
    "\n",
    "# Use filter to find employees eligible for increment\n",
    "filtered_df = df.filter(F.col(\"HireDate\") <= two_years_ago).withColumn(\"NewSalary\", F.col(\"Salary\") * 1.1)\n",
    "non_filtered_df = df.filter(F.col(\"HireDate\") > two_years_ago).withColumn(\"NewSalary\", F.col(\"Salary\"))\n",
    "\n",
    "# Union results for the final output\n",
    "final_incremented_df = filtered_df.union(non_filtered_df)\n",
    "final_incremented_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
